
@inproceedings{johnson2013accelerating,
  title={Accelerating stochastic gradient descent using predictive variance reduction},
  author={Johnson, Rie and Zhang, Tong},
  booktitle={NIPS},
  year={2013}
}

@inproceedings{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle={ICLR},
  year={2015}
}
@article{adadelta,
  author    = {M. D. Zeiler},
  title     = {{ADADELTA:} An Adaptive Learning Rate Method},
  journal   = {arXiv:1212.5701},
  year      = {2012},
}

@misc{rmsprop,
  title={{Lecture 6.5---RmsProp: Divide the gradient by a running average of its recent magnitude}},
  author={Tieleman, T. and Hinton, G.},
  howpublished={COURSERA: Neural Networks for Machine Learning},
  year={2012}
}

@inproceedings{Defazio2019,
 author = {Defazio, Aaron and Bottou, Leon},
 booktitle = {NeurIPS},
 title = {On the Ineffectiveness of Variance Reduced Optimization for Deep Learning},
 year = {2019}
}

@inproceedings{Cutkosky2019storm,
 author = {Cutkosky, Ashok and Orabona, Francesco},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Momentum-Based Variance Reduction in Non-Convex SGD},
 year = {2019}
}

@article{john2011adagrad,
author = {Duchi, John and Hazan, Elad and Singer, Yoram},
title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
year = {2011},
issue_date = {2/1/2011},
publisher = {JMLR.org},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
}

@inproceedings{dauphin2019metainit,
 author = {Dauphin, Yann N and Schoenholz, Samuel},
 booktitle = {NeurIPS},
 title = {MetaInit: Initializing learning by learning to initialize},
 year = {2019}
}


@conference{he2015residual,
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  title = {Deep Residual Learning for Image Recognition},
  year = 2015
}


